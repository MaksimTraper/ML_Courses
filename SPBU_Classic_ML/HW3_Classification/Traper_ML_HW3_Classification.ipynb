{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNa-Hf2lXyZW"
   },
   "source": [
    "# Задача 3. Сравнение методов классификации\n",
    "\n",
    "## Список задач\n",
    "1. Самостоятельно реализовать один из методов классификации, с возможностью настройки гиперпараметров.\n",
    "2. Взять данные для предсказания заболеваний сердца.\n",
    "3. Считать данные, выполнить первичный анализ данных, при необходимости произвести чистку данных (Data Cleaning).\n",
    "4. Выполнить разведочный анализ (EDA), использовать визуализацию, сделать выводы, которые могут быть полезны при дальнейшем решении задачи классификации.\n",
    "5. При необходимости выполнить полезные преобразования данных (например, трансформировать категариальные признаки в количественные), убрать ненужные признаки, создать новые (Feature Engineering).\n",
    "6. Используя подбор гиперпараметров, кросс-валидацию и при необходимости масштабирование данных, добиться наилучшего качества предсказания от Вашей реализации на выделенной заранее тестовой выборке.\n",
    "7. Повторить предыдущий пункт для библиотечных реализаций (например, из sklearn) всех пройденных методов классификации (logistic regression, svm, knn, naive bayes, decision tree).\n",
    "8. Сравнить все обученные модели, построить их confusion matrices. Сделать выводы о полученных моделях в рамках решения задачи классификации на выбранных данных.\n",
    "9. Реализовать еще один из методов классификации и добавить его в сравнение.\n",
    "10. Найти данные, на которых интересно будет решать задачу классификации. Повторить все пункты задания на новых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/9. Самостоятельно реализовать два метода классификации, с возможностью настройки гиперпараметров.\n",
    "Реализую дерево решений (Decision Tree) по алгоритму CART и метод опорных векторов (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"\n",
    "    Класс метрик качества для задач классификации и кластеризации\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini(y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Вычисляем коэффициент Gini для вектора целевых переменных\n",
    "\n",
    "        Параметры:\n",
    "            y (np.ndarray): Одномерный массив (целочисленный вектор)\n",
    "\n",
    "        Возвращает:\n",
    "            float: Значение коэффициента Gini\n",
    "        \"\"\"\n",
    "        count_targets = len(y)\n",
    "        if count_targets == 0:\n",
    "            return 0.0\n",
    "\n",
    "        _, count_each_target = np.unique(y, return_counts=True)\n",
    "        probabilities = count_each_target / count_targets\n",
    "        return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def gini_split(left_y: np.ndarray, right_y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Вычисляем коэффициент Gini для узла при выбранном пороге\n",
    "\n",
    "        Параметры:\n",
    "            left_y: Массив целевых переменных для левой ветви.\n",
    "            right_y: Массив целевых переменных для правой ветви.\n",
    "\n",
    "        Возвращает:\n",
    "            float: Взвешенное значение Gini для разбиения.\n",
    "        \"\"\"\n",
    "        count_objects = len(left_y) + len(right_y)\n",
    "\n",
    "        left_leaf_loss = Metrics.gini(left_y)\n",
    "        right_leaf_loss = Metrics.gini(right_y)\n",
    "        weighted_gini = ((len(left_y) / count_objects) * left_leaf_loss) + \\\n",
    "                        ((len(right_y) / count_objects) * right_leaf_loss)\n",
    "\n",
    "        return weighted_gini, left_leaf_loss, right_leaf_loss\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Класс узла дерева\n",
    "\n",
    "    Параметры:\n",
    "        X: подвыборка признаков в узле\n",
    "        y: подвыборка целевых переменных в узле\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X: pl.DataFrame = None, y: np.ndarray = None, depth: int = 0):\n",
    "        self.left_node = None\n",
    "        self.right_node = None\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "\n",
    "        self.score = Metrics.gini(y) if y is not None else None\n",
    "\n",
    "        self.depth = depth\n",
    "\n",
    "    def create_child_nodes(self, metric='Gini', max_depth=3, min_samples_split=2):\n",
    "        \"\"\"\n",
    "        Функция создания дочерних узлов, присвоение им выборки соответствующих целевых переменных\n",
    "\n",
    "        Параметры:\n",
    "            metric: выбранная метрика качества\n",
    "            max_depth: максимальная глубина дерева\n",
    "            min_samples_split: минимальное количество образцов для разделения\n",
    "\n",
    "        Возвращает:\n",
    "            None\n",
    "        \"\"\"\n",
    "        if self.depth >= max_depth or len(self.y) < min_samples_split or self.score == 0:\n",
    "            return\n",
    "\n",
    "        best_feature, best_threshold, best_score, left_indices, right_indices = self.__choose_best_split(metric)\n",
    "        if best_feature is None:\n",
    "            return\n",
    "\n",
    "        self.feature = best_feature\n",
    "        self.threshold = best_threshold\n",
    "\n",
    "        X_left = self.X[left_indices]\n",
    "        y_left = self.y[left_indices]\n",
    "        X_right = self.X[right_indices]\n",
    "        y_right = self.y[right_indices]\n",
    "\n",
    "        self.left_node = Node(X_left, y_left, depth=self.depth + 1)\n",
    "        self.right_node = Node(X_right, y_right, depth=self.depth + 1)\n",
    "\n",
    "        self.left_node.create_child_nodes(metric, max_depth, min_samples_split)\n",
    "        self.right_node.create_child_nodes(metric, max_depth, min_samples_split)\n",
    "\n",
    "    def __choose_best_split(self, metric='Gini'):\n",
    "        \"\"\"\n",
    "        Вычисляет оптимальный признак и порог для узла, исходя из выбранной метрики\n",
    "\n",
    "        Возвращает:\n",
    "            best_feature, best_threshold, best_score, left_indices, right_indices\n",
    "        \"\"\"\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_score = np.inf\n",
    "        best_left_indices = None\n",
    "        best_right_indices = None\n",
    "\n",
    "        features = self.X.columns\n",
    "\n",
    "        for feature in features:\n",
    "            X_column = self.X[feature].to_numpy()\n",
    "            thresholds, scores, left_indices_list, right_indices_list = self.__find_thresholds(X_column, self.y, metric)\n",
    "\n",
    "            if len(scores) == 0:\n",
    "                continue\n",
    "\n",
    "            min_score_index = np.argmin(scores)\n",
    "            score = scores[min_score_index]\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_threshold = thresholds[min_score_index]\n",
    "                best_feature = feature\n",
    "                best_left_indices = left_indices_list[min_score_index]\n",
    "                best_right_indices = right_indices_list[min_score_index]\n",
    "\n",
    "        return best_feature, best_threshold, best_score, best_left_indices, best_right_indices\n",
    "\n",
    "    def __find_thresholds(self, X_column: np.ndarray, y: np.ndarray, metric='Gini'):\n",
    "        \"\"\"\n",
    "        Находит все возможные пороги для признака и вычисляет метрику для каждого\n",
    "\n",
    "        Возвращает:\n",
    "            thresholds, scores, left_indices_list, right_indices_list\n",
    "        \"\"\"\n",
    "        thresholds = []\n",
    "        scores = []\n",
    "        left_indices_list = []\n",
    "        right_indices_list = []\n",
    "\n",
    "        sorted_indices = np.argsort(X_column)\n",
    "        X_sorted = X_column[sorted_indices]\n",
    "        y_sorted = y[sorted_indices]\n",
    "\n",
    "        unique_values = np.unique(X_sorted)\n",
    "        if len(unique_values) == 1:\n",
    "            return thresholds, scores, left_indices_list, right_indices_list\n",
    "\n",
    "        for i in range(1, len(X_sorted)):\n",
    "            if X_sorted[i] == X_sorted[i - 1]:\n",
    "                continue  # пропускаем повторяющиеся значения\n",
    "\n",
    "            threshold = (X_sorted[i] + X_sorted[i - 1]) / 2\n",
    "\n",
    "            left_indices = sorted_indices[:i]\n",
    "            right_indices = sorted_indices[i:]\n",
    "\n",
    "            left_y = y[left_indices]\n",
    "            right_y = y[right_indices]\n",
    "\n",
    "            if metric == 'Gini':\n",
    "                score, _, _ = Metrics.gini_split(left_y, right_y)\n",
    "            else:\n",
    "                raise ValueError(f\"Неизвестная метрика: {metric}\")\n",
    "\n",
    "            thresholds.append(threshold)\n",
    "            scores.append(score)\n",
    "            left_indices_list.append(left_indices)\n",
    "            right_indices_list.append(right_indices)\n",
    "\n",
    "        return thresholds, scores, left_indices_list, right_indices_list\n",
    "\n",
    "    def majority_class(self):\n",
    "        \"\"\"\n",
    "        Возвращает класс большинства в листе.\n",
    "        \"\"\"\n",
    "        values, counts = np.unique(self.y, return_counts=True)\n",
    "        return values[np.argmax(counts)]\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "    Класс решающего дерева, реализованного по алгоритму CART\n",
    "\n",
    "    Параметры:\n",
    "        max_depth: максимальная глубина дерева\n",
    "        metric: метрика качества\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth: int = 3, metric: str = 'Gini', min_samples_split: int = 2):\n",
    "        self.max_depth = max_depth\n",
    "        self.metric = metric\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "    \n",
    "    def encode_categorical_features(self, X: pl.DataFrame):\n",
    "        \"\"\"\n",
    "        Метод кодирования категориальных переменных с помощью One-Hot Encoding\n",
    "\n",
    "        Параметры:\n",
    "            X: датафрейм данных\n",
    "\n",
    "        Возвращает:\n",
    "            pl.DataFrame: датафрейм данных с закодированными категориальными переменными\n",
    "        \"\"\"\n",
    "        categorical_features = [feature for feature, dtype in X.schema.items() if dtype == pl.Utf8]\n",
    "        if len(categorical_features) == 0:\n",
    "            return X\n",
    "\n",
    "        X_encoded = X.to_pandas()\n",
    "        X_encoded = pd.get_dummies(X_encoded, columns=categorical_features)\n",
    "        return pl.from_pandas(X_encoded)\n",
    "    \n",
    "    def fit(self, X: Union[np.ndarray, pd.DataFrame, pl.DataFrame], y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Метод построения решающего дерева на основе данных\n",
    "\n",
    "        Параметры:\n",
    "            X: датафрейм данных\n",
    "            y: вектор целевых переменных\n",
    "\n",
    "        Возвращает:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # Преобразование данных в pl.DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = pl.from_pandas(X)\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            X = pl.DataFrame(X)\n",
    "        elif not isinstance(X, pl.DataFrame):\n",
    "            raise ValueError(\"X должен быть pd.DataFrame, pl.DataFrame или np.ndarray\")\n",
    "\n",
    "        # Кодирование категориальных признаков\n",
    "        X = self.encode_categorical_features(X)\n",
    "\n",
    "        self.features = X.columns\n",
    "\n",
    "        self.root = Node(X, y, depth=0)\n",
    "        self.root.create_child_nodes(metric=self.metric, max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: Union[np.ndarray, pd.DataFrame, pl.DataFrame]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Метод предсказания целевой метки объектов\n",
    "\n",
    "        Параметры:\n",
    "            X: датафрейм данных\n",
    "\n",
    "        Возвращает:\n",
    "            np.ndarray: список предсказанных целевых меток\n",
    "        \"\"\"\n",
    "        # Преобразование данных в pl.DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = pl.from_pandas(X)\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            X = pl.DataFrame(X, columns=self.features)\n",
    "        elif not isinstance(X, pl.DataFrame):\n",
    "            raise ValueError(\"X должен быть pd.DataFrame, pl.DataFrame или np.ndarray\")\n",
    "\n",
    "        # Кодирование категориальных признаков\n",
    "        X = self.encode_categorical_features(X)\n",
    "\n",
    "        y_pred = []\n",
    "        \n",
    "        for row_idx in range(X.height):\n",
    "            current_node = self.root\n",
    "            while current_node.left_node is not None and current_node.right_node is not None:\n",
    "                if current_node.feature not in X.columns:\n",
    "                    break  # если признак отсутствует после кодирования\n",
    "                value = X[current_node.feature][row_idx]\n",
    "                if value <= current_node.threshold:\n",
    "                    current_node = current_node.left_node\n",
    "                else:\n",
    "                    current_node = current_node.right_node\n",
    "            y_pred.append(current_node.majority_class())\n",
    "    \n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def pruning(self, X_val: Union[np.ndarray, pd.DataFrame, pl.DataFrame], y_val: np.ndarray, alpha: float = 0.0):\n",
    "        \"\"\"\n",
    "        Обрезка дерева (pruning) с использованием метода минимальной стоимости сложения (Cost-Complexity Pruning)\n",
    "\n",
    "        Параметры:\n",
    "            X_val: валидационные данные\n",
    "            y_val: целевые метки для валидационных данных\n",
    "            alpha (float): параметр сложности модели\n",
    "\n",
    "        Возвращает:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # Реализация прунинга на основе минимизации функционала с параметром alpha\n",
    "        # Эта часть может быть довольно сложной и требует полноценной реализации алгоритма CCP\n",
    "        # Ниже приведен упрощенный пример\n",
    "\n",
    "        # Вычисляем предсказания на валидационном наборе до прунинга\n",
    "        y_pred = self.predict(X_val)\n",
    "        best_accuracy = np.mean(y_pred == y_val)\n",
    "        best_tree = self.root\n",
    "\n",
    "        def prune_node(node: Node):\n",
    "            if node.left_node is None or node.right_node is None:\n",
    "                return\n",
    "\n",
    "            # Сохраняем ссылки на дочерние узлы\n",
    "            left_backup = node.left_node\n",
    "            right_backup = node.right_node\n",
    "\n",
    "            # Обрезаем узлы\n",
    "            node.left_node = None\n",
    "            node.right_node = None\n",
    "\n",
    "            # Проверяем качество на валидационной выборке\n",
    "            y_pred = self.predict(X_val)\n",
    "            accuracy = np.mean(y_pred == y_val)\n",
    "\n",
    "            # Если качество улучшилось или не изменилось, оставляем узел обрезанным\n",
    "            if accuracy >= best_accuracy - alpha:\n",
    "                best_accuracy = accuracy\n",
    "                best_tree = self.root\n",
    "            else:\n",
    "                # Возвращаем дочерние узлы обратно\n",
    "                node.left_node = left_backup\n",
    "                node.right_node = right_backup\n",
    "\n",
    "                # Рекурсивно пытаемся обрезать дочерние узлы\n",
    "                prune_node(node.left_node)\n",
    "                prune_node(node.right_node)\n",
    "\n",
    "        prune_node(self.root)\n",
    "        self.root = best_tree\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод опорных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSVM:\n",
    "    \"\"\"\n",
    "    Класс метода опорных векторов, линейно разделяющего данные\n",
    "\n",
    "    Параметры:\n",
    "        X: датасет признаков\n",
    "        y: вектор целевых меток\n",
    "        С: коэффициент регуляризации\n",
    "        kernel: ядро\n",
    "    \"\"\"\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, C: float = 0.0):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "        self.count_objects = self.X.shape[0]\n",
    "        self.count_features = self.X.shape[1]\n",
    "\n",
    "        self.C = C\n",
    "        self.W = np.zeros(self.count_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "    def __gradient_descent(self, threshold: float = 1e-3, lr: float = 1e-2, max_iter: int = 10000):\n",
    "        \"\"\"\n",
    "        Подбор параметров линейно разделяющего SVM методом градиентного спуска\n",
    "\n",
    "        Параметры:\n",
    "            threshold: порог, если меньше которого будет изменение, то алгоритм остановится\n",
    "            lr: скорость обучения\n",
    "            max_iter: максимальное количество итераций\n",
    "\n",
    "        Возвращает:\n",
    "            self\n",
    "        \"\"\"\n",
    "        for step in range(max_iter):\n",
    "            hinge_loss_gradient = 1 - self.y * (self.W.dot(self.X.T) + self.b)\n",
    "            mask = hinge_loss_gradient > 0\n",
    "\n",
    "            dW = self.W - self.C * np.sum((self.y[mask][:, None] * self.X[mask, :]), axis=0)\n",
    "            db = -self.C * np.sum(self.y[mask])\n",
    "\n",
    "            self.W -= lr * dW\n",
    "            self.b -= lr * db\n",
    "            \n",
    "            # Условие выхода\n",
    "            if np.linalg.norm(dW) < threshold and abs(db) < threshold:\n",
    "                break\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Обучение классификатора SVM\n",
    "\n",
    "        Возвращает:\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.__gradient_descent()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: Union[np.ndarray, pd.DataFrame, pl.DataFrame]):\n",
    "        if isinstance(X, (pl.DataFrame, pd.DataFrame)):\n",
    "            X = X.to_numpy()\n",
    "\n",
    "        if self.W is None or self.b is None:\n",
    "            raise ValueError(\"Модель ещё не обучена. Сначала вызовите метод `fit`.\")\n",
    "\n",
    "        decision = np.dot(X, self.W) + self.b\n",
    "        # Применяем функцию знака\n",
    "        return np.sign(decision)\n",
    "\n",
    "class NonlinearSVM:\n",
    "    \"\"\"\n",
    "    Класс метода опорных вектор, нелинейно разделяющего данные\n",
    "\n",
    "    Параметры:\n",
    "        X: датасет признаков\n",
    "        y: вектор целевых меток\n",
    "        С: коэффициент регуляризации\n",
    "    \"\"\"\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, C: float = 0.0):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "        self.count_objects = self.X.shape[0]\n",
    "        self.count_features = self.X.shape[1]\n",
    "\n",
    "        self.C = C\n",
    "        self.W = np.zeros(self.count_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "class SVM:\n",
    "    \"\"\"\n",
    "    Класс метода опорных векторов, линейно разделяющего данные\n",
    "\n",
    "    Параметры:\n",
    "        X: датасет признаков\n",
    "        y: вектор целевых меток\n",
    "        С: коэффициент регуляризации\n",
    "        kernel: ядро\n",
    "    \"\"\"\n",
    "    def __init__(self, X: Union[np.ndarray, pd.DataFrame, pl.DataFrame], \n",
    "                 y: Union[np.ndarray, pd.DataFrame, pl.DataFrame],\n",
    "                 C: float = 0.0, kernel: str = 'rbf'):\n",
    "        if isinstance(X, (pl.DataFrame, pd.DataFrame)):\n",
    "            X = X.to_numpy()\n",
    "        self.X = X\n",
    "\n",
    "        if isinstance(y, (pl.DataFrame, pd.DataFrame, pl.Series, pd.Series)):\n",
    "            y = y.to_numpy()\n",
    "        self.y = y\n",
    "    \n",
    "        self.count_objects = self.X.shape[0]\n",
    "        self.count_features = self.X.shape[1]\n",
    "\n",
    "        self.C = C\n",
    "        self.W = np.zeros(self.count_features)\n",
    "        self.b = 0.0\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.svm = None\n",
    "\n",
    "    def __choose_fit_pipeline(self):\n",
    "        if self.kernel == 'linear':\n",
    "            self.svm = LinearSVM(self.X_train, self.y_train, C=1.0).fit()\n",
    "        elif self.kernel == 'rbf':\n",
    "            self.svm = NonlinearSVM()\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Обучение классификатора SVM\n",
    "\n",
    "        Возвращает:\n",
    "            self\n",
    "        \"\"\"\n",
    "        self.__choose_fit_pipeline()\n",
    "        return self\n",
    "\n",
    "    def __choose_fit_pipeline(self):\n",
    "        if self.kernel == 'linear':\n",
    "            self.svm = LinearSVM(self.X_train, self.y_train, C=1.0).predict()\n",
    "        elif self.kernel == 'rbf':\n",
    "            self.svm = NonlinearSVM().fit()\n",
    "\n",
    "    def predict(self, X: Union[np.ndarray, pd.DataFrame, pl.DataFrame]):\n",
    "        \"\"\"\n",
    "        Предсказание класса объекта\n",
    "\n",
    "        Параметры:\n",
    "            X: датафрейм объектов\n",
    "\n",
    "        Возвращает:\n",
    "            np.array: массив предсказанных целевых меток\n",
    "        \"\"\"\n",
    "        if isinstance(X, (pl.DataFrame, pd.DataFrame)):\n",
    "            X = X.to_numpy()\n",
    "\n",
    "        if self.W is None or self.b is None:\n",
    "            raise ValueError(\"Модель ещё не обучена. Сначала вызовите метод `fit`.\")\n",
    "\n",
    "        decision = np.dot(X, self.W) + self.b\n",
    "        # Применяем функцию знака\n",
    "        return np.sign(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(X_train, y_train, C=1.0)\n",
    "svm.fit()\n",
    "\n",
    "predictions = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree()\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "predictions_tree = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (205,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>1</td></tr><tr><td>&hellip;</td></tr><tr><td>0</td></tr><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>1</td></tr><tr><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (205,)\n",
       "Series: 'target' [i64]\n",
       "[\n",
       "\t0\n",
       "\t1\n",
       "\t0\n",
       "\t1\n",
       "\t1\n",
       "\t…\n",
       "\t0\n",
       "\t0\n",
       "\t1\n",
       "\t1\n",
       "\t1\n",
       "]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X type: <class 'numpy.ndarray'>, y type: <class 'numpy.ndarray'>\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Пример данных\n",
    "X = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "y = np.array([1, -1, 1])\n",
    "\n",
    "# Обучение модели\n",
    "svm = SVM(X, y, C=1.0)\n",
    "svm.fit()\n",
    "\n",
    "# Предсказание\n",
    "X_test = np.array([[2, 2], [4, 5]])\n",
    "predictions = svm.predict(X_test)\n",
    "print(predictions)  # Результаты: [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('heart.csv')\n",
    "\n",
    "targets = df['target']\n",
    "features = df.drop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, shuffle=True, stratify=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X type: <class 'numpy.ndarray'>, y type: <class 'polars.series.series.Series'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "selecting rows by passing a boolean mask to `__getitem__` is not supported\n\nHint: Use the `filter` method instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVM(X_train, y_train, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43msvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[52], line 66\u001b[0m, in \u001b[0;36mSVM.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    Обучение линейно разделяющего классификатора SVM\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03m    Возвращает:\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m        self\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[1;32mIn[52], line 47\u001b[0m, in \u001b[0;36mSVM.__gradient_descent\u001b[1;34m(self, threshold, lr, max_iter)\u001b[0m\n\u001b[0;32m     43\u001b[0m mask \u001b[38;5;241m=\u001b[39m hinge_loss_gradient \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[mask, :]\n\u001b[1;32m---> 47\u001b[0m dW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m[:, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[mask, :]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     48\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[mask])\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m*\u001b[39m dW\n",
      "File \u001b[1;32mc:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\polars\\series\\series.py:1280\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m, key: SingleIndexSelector \u001b[38;5;241m|\u001b[39m MultiIndexSelector\n\u001b[0;32m   1254\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;124;03m    Get part of the Series as a new Series or scalar.\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;124;03m    ]\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_series_item_by_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\polars\\_utils\\getitem.py:82\u001b[0m, in \u001b[0;36mget_series_item_by_key\u001b[1;34m(s, key)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _select_elements_by_index(s, indices)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, pl\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m---> 82\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_series_to_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _select_elements_by_index(s, indices)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _check_for_numpy(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\polars\\_utils\\getitem.py:352\u001b[0m, in \u001b[0;36m_convert_series_to_indices\u001b[1;34m(s, size)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_integer():\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Boolean:\n\u001b[1;32m--> 352\u001b[0m         \u001b[43m_raise_on_boolean_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot treat Series of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as indices\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Maksim\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\polars\\_utils\\getitem.py:447\u001b[0m, in \u001b[0;36m_raise_on_boolean_mask\u001b[1;34m()\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_on_boolean_mask\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m    443\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselecting rows by passing a boolean mask to `__getitem__` is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHint: Use the `filter` method instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n\u001b[1;32m--> 447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mTypeError\u001b[0m: selecting rows by passing a boolean mask to `__getitem__` is not supported\n\nHint: Use the `filter` method instead."
     ]
    }
   ],
   "source": [
    "svm = SVM(X_train, y_train, C=1.0)\n",
    "svm.fit()\n",
    "\n",
    "predictions = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yz3-pAdOZBYh",
    "pW4msAz2j0FG",
    "Frb4W3BUo7py",
    "rJ5xYIj4xfs6",
    "_M0TM2Dm0sGi",
    "rIPBXJVp1yVn",
    "xCGM34iX170T",
    "2mT-Aa5s2CYI"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
